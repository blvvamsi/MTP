{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions required\n",
    "\n",
    "# XML PARSER\n",
    "def get_list(path):\n",
    "    tree=ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    text_list = []\n",
    "    opinion_list = []\n",
    "    for review in root.findall('Review'):\n",
    "        text_string=\"\"\n",
    "        opinion_inner_list=[]\n",
    "        for sent in review.findall('./sentences/sentence'):\n",
    "            text_string= text_string+ \" \"+ sent.find('text').text\n",
    "        text_list.append(text_string)\n",
    "        for opinion in review.findall('./Opinions/Opinion'):\n",
    "            opinion_dict = {\n",
    "                opinion.get('category').replace('#','_'): opinion.get('polarity')\n",
    "            }\n",
    "            opinion_inner_list.append(opinion_dict)\n",
    "        opinion_list.append(opinion_inner_list)\n",
    "    return text_list,opinion_list\n",
    "\n",
    "\n",
    "\n",
    "def get_most_common_aspect(opinion_list):\n",
    "    import nltk\n",
    "    opinion= []\n",
    "    for inner_list in opinion_list:\n",
    "        for _dict in inner_list:\n",
    "            for key in _dict:\n",
    "                opinion.append(key)\n",
    "    most_common_aspect = [k for k,v in nltk.FreqDist(opinion).most_common(20)]\n",
    "    return most_common_aspect\n",
    "\n",
    "\n",
    "def get_data_frame(text_list,opinion_list,most_common_aspect):\n",
    "    data={'Review':text_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    if opinion_list:\n",
    "        for inner_list in opinion_list:\n",
    "            for _dict in inner_list:\n",
    "                for key in _dict:\n",
    "                    if key in most_common_aspect:\n",
    "                        df.loc[opinion_list.index(inner_list),key]=_dict[key]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_aspect_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','negative','neutral','conflict'],[1,1,1,1])\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_positive_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_negative_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative'],[1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['positive','neutral','conflict'],[0,0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_neutral_data_frame(df,most_common_aspect):\n",
    "    for common_aspect in most_common_aspect:\n",
    "        df[common_aspect]=df[common_aspect].replace(['neutral','conflict'],[1,1])\n",
    "        df[common_aspect]=df[common_aspect].replace(['negative','positive'],[0,0])\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def posTag(review):\n",
    "    tagged_text_list=[]\n",
    "    for text in review:\n",
    "        tagged_text_list.append(stanford_tag.tag(word_tokenize(text)))\n",
    "    return tagged_text_list\n",
    "\n",
    "\n",
    "def filterTag(tagged_review):\n",
    "    final_text_list=[]\n",
    "    for text_list in tagged_review:\n",
    "        final_text=[]\n",
    "        for word,tag in text_list:\n",
    "            if tag in ['NN','NNS','NNP','NNPS','RB','RBR','RBS','JJ','JJR','JJS','VB','VBD','VBG','VBN','VBP','VBZ']:\n",
    "                final_text.append(word)\n",
    "        final_text_list.append(' '.join(final_text))\n",
    "    return final_text_list\n",
    "\n",
    "\n",
    "def get_dict_aspect(y,most_common_aspect):\n",
    "    position=[]\n",
    "    for innerlist in y:\n",
    "        position.append([i for i, j in enumerate(innerlist) if j == 1])\n",
    "    sorted_common=sorted(most_common_aspect)\n",
    "    dict_aspect=[]\n",
    "    for innerlist in position:\n",
    "        inner_dict={}\n",
    "        for word in sorted_common:\n",
    "            if sorted_common.index(word) in innerlist:\n",
    "                inner_dict[word]= 5\n",
    "            else:\n",
    "                inner_dict[word]=0\n",
    "        dict_aspect.append(inner_dict)\n",
    "    return dict_aspect\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"ABSA16_Laptops_Train_English_SB2.xml\"\n",
    "testing_path = \"EN_LAPT_SB2_TEST.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 'stanford-postagger-3.9.2-src.jar'\n",
    "from nltk.tag.stanford import StanfordPOSTagger as POS_Tag\n",
    "from nltk import word_tokenize\n",
    "_path_to_model =  'models/english-bidirectional-distsim.tagger' \n",
    "_path_to_jar =  'stanford-postagger.jar'\n",
    "stanford_tag = POS_Tag(model_filename=_path_to_model, path_to_jar=_path_to_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n"
     ]
    }
   ],
   "source": [
    "train_text_list,train_opinion_list = get_list(training_path)\n",
    "most_common_aspect = get_most_common_aspect(train_opinion_list)\n",
    "tagged_text_list_train=joblib.load('tagged_text_list_train.pkl')\n",
    "final_train_text_list=filterTag(tagged_text_list_train)\n",
    "\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_train_aspect = get_aspect_data_frame(df_train,most_common_aspect)\n",
    "df_train_aspect = df_train_aspect.reindex_axis(sorted(df_train_aspect.columns), axis=1)\n",
    "\n",
    "\n",
    "test_text_list,test_opinion_list = get_list(testing_path)\n",
    "\n",
    "tagged_text_list_test=joblib.load('tagged_text_list_test.pkl')\n",
    "\n",
    "final_test_text_list=filterTag(tagged_text_list_test)\n",
    "\n",
    "\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "df_test_aspect = get_aspect_data_frame(df_test,most_common_aspect)\n",
    "df_test_aspect = df_test_aspect.reindex_axis(sorted(df_test_aspect.columns), axis=1)\n",
    "\n",
    "X_train= df_train_aspect.Review\n",
    "y_train = df_train_aspect.drop('Review',1)\n",
    "\n",
    "\n",
    "X_test = df_test_aspect.Review\n",
    "y_test = df_test_aspect.drop('Review',1)\n",
    "\n",
    "import numpy as np\n",
    "y_train = np.asarray(y_train, dtype=np.int64)\n",
    "y_test = np.asarray(y_test, dtype=np.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "vect = CountVectorizer(max_df=1.0,stop_words='english')  \n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "C = 1.0 #SVregularization parameter\n",
    "svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb_classif.predict(X_test_dtm)\n",
    "y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "y_pred_class_sgd = sgd.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.05\n",
      "0.05\n",
      "0.0125\n",
      "0.75\n",
      "0.7112299465240641\n",
      "0.7321937321937322\n",
      "0.6807817589576547\n",
      "0.4576271186440678\n",
      "0.6440677966101694\n",
      "0.6222760290556901\n",
      "0.5060532687651331\n",
      "0.5684210526315788\n",
      "0.6759847522236341\n",
      "0.6727748691099477\n",
      "0.5805555555555555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.14      0.24        14\n",
      "           1       0.71      0.50      0.59        24\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.76      0.64      0.69        39\n",
      "           8       1.00      1.00      1.00        80\n",
      "           9       0.44      0.17      0.24        24\n",
      "          10       0.62      0.70      0.65        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.57      0.30      0.39        27\n",
      "          13       0.57      0.45      0.50        29\n",
      "          14       0.77      0.33      0.47        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.60      0.27      0.37        11\n",
      "\n",
      "   micro avg       0.75      0.46      0.57       413\n",
      "   macro avg       0.33      0.22      0.26       413\n",
      "weighted avg       0.57      0.46      0.49       413\n",
      " samples avg       0.78      0.50      0.57       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.68      0.71      0.69        24\n",
      "           2       0.86      0.50      0.63        12\n",
      "           3       0.12      0.25      0.17         4\n",
      "           4       0.56      0.43      0.49        21\n",
      "           5       0.75      0.38      0.50         8\n",
      "           6       0.20      0.14      0.17         7\n",
      "           7       0.74      0.67      0.70        39\n",
      "           8       1.00      0.97      0.99        80\n",
      "           9       0.63      0.50      0.56        24\n",
      "          10       0.68      0.74      0.71        46\n",
      "          11       0.33      0.40      0.36         5\n",
      "          12       0.83      0.74      0.78        27\n",
      "          13       0.56      0.66      0.60        29\n",
      "          14       0.60      0.40      0.48        30\n",
      "          15       0.67      0.50      0.57         4\n",
      "          16       0.18      0.22      0.20         9\n",
      "          17       0.80      0.27      0.40        15\n",
      "          18       1.00      0.25      0.40         4\n",
      "          19       0.60      0.27      0.37        11\n",
      "\n",
      "   micro avg       0.71      0.64      0.68       413\n",
      "   macro avg       0.63      0.50      0.53       413\n",
      "weighted avg       0.72      0.64      0.67       413\n",
      " samples avg       0.73      0.65      0.66       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       0.65      0.71      0.68        24\n",
      "           2       1.00      0.42      0.59        12\n",
      "           3       0.17      0.25      0.20         4\n",
      "           4       0.64      0.43      0.51        21\n",
      "           5       1.00      0.25      0.40         8\n",
      "           6       0.33      0.14      0.20         7\n",
      "           7       0.74      0.67      0.70        39\n",
      "           8       1.00      0.96      0.98        80\n",
      "           9       0.61      0.46      0.52        24\n",
      "          10       0.70      0.72      0.71        46\n",
      "          11       0.25      0.20      0.22         5\n",
      "          12       0.83      0.74      0.78        27\n",
      "          13       0.54      0.66      0.59        29\n",
      "          14       0.61      0.37      0.46        30\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.20      0.22      0.21         9\n",
      "          17       1.00      0.20      0.33        15\n",
      "          18       1.00      0.25      0.40         4\n",
      "          19       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.73      0.62      0.67       413\n",
      "   macro avg       0.69      0.46      0.51       413\n",
      "weighted avg       0.75      0.62      0.66       413\n",
      " samples avg       0.74      0.63      0.65       413\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        14\n",
      "           1       0.67      0.67      0.67        24\n",
      "           2       1.00      0.17      0.29        12\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.33      0.14      0.20        21\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.86      0.49      0.62        39\n",
      "           8       1.00      0.94      0.97        80\n",
      "           9       0.50      0.25      0.33        24\n",
      "          10       0.67      0.61      0.64        46\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.64      0.52      0.57        27\n",
      "          13       0.53      0.66      0.58        29\n",
      "          14       0.52      0.47      0.49        30\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         9\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.25      0.25      0.25         4\n",
      "          19       0.67      0.36      0.47        11\n",
      "\n",
      "   micro avg       0.68      0.51      0.58       413\n",
      "   macro avg       0.41      0.30      0.33       413\n",
      "weighted avg       0.62      0.51      0.54       413\n",
      " samples avg       0.71      0.56      0.58       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "print(metrics.accuracy_score(y_test,y_pred_class_sgd))\n",
    "print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2:\n",
    "#Generating extra feature that indicates which aspect category is present in the review\n",
    "train_dict_aspect=get_dict_aspect(y_train, most_common_aspect)\n",
    "d_train=DictVectorizer() \n",
    "X_train_aspect_dtm = d_train.fit_transform(train_dict_aspect)\n",
    "\n",
    "#y_test is used to generated extra feature in order to test the performance of 2nd classifer.\n",
    "#Use y_pred_class_svc(Highest performer for aspect classification) as input for extra feature to test the overall performace.\n",
    "test_dict_aspect=get_dict_aspect(y_test,most_common_aspect)\n",
    "d_test=DictVectorizer() \n",
    "X_test_aspect_dtm = d_test.fit_transform(test_dict_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(df_train,df_test,X_train_aspect_dtm,X_test_aspect_dtm):\n",
    "    \n",
    "    df_train = df_train.reindex_axis(sorted(df_train_positive.columns), axis=1)\n",
    "    df_test = df_test.reindex_axis(sorted(df_test_positive.columns), axis=1)\n",
    "\n",
    "    import numpy as np\n",
    "    X_train = df_train.Review\n",
    "    y_train = df_train.drop('Review',1)\n",
    "    y_train = np.asarray(y_train, dtype=np.int64)\n",
    "\n",
    "    X_test = df_test.Review\n",
    "    y_test = df_test.drop('Review',1)\n",
    "    y_test = np.asarray(y_test, dtype=np.int64)\n",
    "\n",
    "    vect_sen = CountVectorizer(stop_words='english',ngram_range=(1,2))  \n",
    "    X_train_dtm = vect_sen.fit_transform(X_train)\n",
    "    X_test_dtm = vect_sen.transform(X_test)\n",
    "\n",
    "    #ombining word vector with extra feature.\n",
    "    from scipy.sparse import hstack\n",
    "    X_train_dtm=hstack((X_train_dtm, X_train_aspect_dtm))\n",
    "    X_test_dtm=hstack((X_test_dtm, X_test_aspect_dtm))\n",
    "\n",
    "    C = 1.0 #SVregularization parameter\n",
    "    nb_classif = OneVsRestClassifier(MultinomialNB()).fit(X_train_dtm, y_train)\n",
    "    svc = OneVsRestClassifier(svm.SVC(kernel='linear', C=C)).fit(X_train_dtm, y_train)\n",
    "    lin_svc = OneVsRestClassifier(svm.LinearSVC(C=C)).fit(X_train_dtm, y_train)\n",
    "    sgd = OneVsRestClassifier(SGDClassifier()).fit(X_train_dtm,y_train)\n",
    "\n",
    "    y_pred_class= nb_classif.predict(X_test_dtm)\n",
    "    y_pred_class_svc = svc.predict(X_test_dtm)\n",
    "    y_pred_class_lin_svc = lin_svc.predict(X_test_dtm)\n",
    "    y_pred_class_sgd = sgd.predict(X_test_dtm)\n",
    "    return (y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(y_test,y_pred_class,y_pred_class_svc,y_pred_class_lin_svc,y_pred_class_sgd):\n",
    "    print(\"Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_lin_svc))\n",
    "    print(metrics.accuracy_score(y_test,y_pred_class_sgd))\n",
    "\n",
    "    print(\"\\nAverage precision:\")\n",
    "    print(metrics.precision_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.precision_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nAverage recall:\")\n",
    "    print(metrics.recall_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.recall_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "    \n",
    "    print(\"\\nAverage f1:\")\n",
    "    print(metrics.f1_score(y_test,y_pred_class,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_lin_svc,average='micro'))\n",
    "    print(metrics.f1_score(y_test,y_pred_class_sgd,average='micro'))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_lin_svc))\n",
    "    print(metrics.classification_report(y_test, y_pred_class_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.15\n",
      "0.35\n",
      "0.3125\n",
      "0.2375\n",
      "\n",
      "Average precision:\n",
      "0.8571428571428571\n",
      "0.7457627118644068\n",
      "0.7560975609756098\n",
      "0.7206477732793523\n",
      "\n",
      "Average recall:\n",
      "0.2608695652173913\n",
      "0.7971014492753623\n",
      "0.6739130434782609\n",
      "0.644927536231884\n",
      "\n",
      "Average f1:\n",
      "0.4\n",
      "0.7705779334500876\n",
      "0.7126436781609194\n",
      "0.6806883365200764\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00        26\n",
      "           8       0.83      0.95      0.89        61\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       1.00      0.39      0.56        36\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00        12\n",
      "          13       0.00      0.00      0.00        18\n",
      "          14       0.00      0.00      0.00        23\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         8\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.86      0.26      0.40       276\n",
      "   macro avg       0.09      0.07      0.07       276\n",
      "weighted avg       0.31      0.26      0.27       276\n",
      " samples avg       0.72      0.26      0.35       276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        12\n",
      "           1       0.67      0.71      0.69        14\n",
      "           2       0.50      1.00      0.67         6\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       0.65      0.73      0.69        15\n",
      "           5       0.75      0.43      0.55         7\n",
      "           6       0.67      0.50      0.57         4\n",
      "           7       0.71      0.77      0.74        26\n",
      "           8       0.89      0.93      0.91        61\n",
      "           9       0.47      0.82      0.60        11\n",
      "          10       0.89      0.89      0.89        36\n",
      "          11       0.75      0.75      0.75         4\n",
      "          12       0.60      0.75      0.67        12\n",
      "          13       0.72      0.72      0.72        18\n",
      "          14       0.75      0.91      0.82        23\n",
      "          15       0.67      0.67      0.67         3\n",
      "          16       0.25      0.14      0.18         7\n",
      "          17       0.80      0.50      0.62         8\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       1.00      0.50      0.67         4\n",
      "\n",
      "   micro avg       0.75      0.80      0.77       276\n",
      "   macro avg       0.70      0.73      0.70       276\n",
      "weighted avg       0.76      0.80      0.77       276\n",
      " samples avg       0.66      0.65      0.62       276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.64      0.64      0.64        14\n",
      "           2       0.60      0.50      0.55         6\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       0.69      0.60      0.64        15\n",
      "           5       1.00      0.14      0.25         7\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.68      0.65      0.67        26\n",
      "           8       0.88      0.92      0.90        61\n",
      "           9       0.44      0.73      0.55        11\n",
      "          10       0.89      0.86      0.87        36\n",
      "          11       1.00      0.50      0.67         4\n",
      "          12       0.45      0.42      0.43        12\n",
      "          13       0.73      0.61      0.67        18\n",
      "          14       0.71      0.65      0.68        23\n",
      "          15       1.00      0.33      0.50         3\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.75      0.38      0.50         8\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.76      0.67      0.71       276\n",
      "   macro avg       0.69      0.55      0.57       276\n",
      "weighted avg       0.74      0.67      0.69       276\n",
      " samples avg       0.67      0.57      0.58       276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        12\n",
      "           1       0.70      0.50      0.58        14\n",
      "           2       0.38      0.50      0.43         6\n",
      "           3       0.67      0.67      0.67         3\n",
      "           4       0.71      0.67      0.69        15\n",
      "           5       0.80      0.57      0.67         7\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.69      0.92      0.79        26\n",
      "           8       0.90      0.75      0.82        61\n",
      "           9       0.38      0.55      0.44        11\n",
      "          10       0.91      0.56      0.69        36\n",
      "          11       0.80      1.00      0.89         4\n",
      "          12       0.48      0.83      0.61        12\n",
      "          13       0.64      0.50      0.56        18\n",
      "          14       0.79      0.65      0.71        23\n",
      "          15       1.00      0.67      0.80         3\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.50      0.12      0.20         8\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.50      0.50      0.50         4\n",
      "\n",
      "   micro avg       0.72      0.64      0.68       276\n",
      "   macro avg       0.64      0.59      0.60       276\n",
      "weighted avg       0.73      0.64      0.67       276\n",
      " samples avg       0.59      0.51      0.52       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For positive sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "df_test_positive = get_positive_data_frame(df_test,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test_positive,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.4875\n",
      "0.4875\n",
      "0.4625\n",
      "0.45\n",
      "\n",
      "Average precision:\n",
      "0.7\n",
      "0.625\n",
      "0.6666666666666666\n",
      "0.66\n",
      "\n",
      "Average recall:\n",
      "0.06422018348623854\n",
      "0.41284403669724773\n",
      "0.3302752293577982\n",
      "0.30275229357798167\n",
      "\n",
      "Average f1:\n",
      "0.11764705882352941\n",
      "0.49723756906077354\n",
      "0.441717791411043\n",
      "0.41509433962264153\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.67      0.33      0.44        18\n",
      "           9       0.00      0.00      0.00         9\n",
      "          10       0.00      0.00      0.00        10\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        12\n",
      "          13       1.00      0.09      0.17        11\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.70      0.06      0.12       109\n",
      "   macro avg       0.08      0.02      0.03       109\n",
      "weighted avg       0.21      0.06      0.09       109\n",
      " samples avg       0.07      0.02      0.03       109\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.67      0.60      0.63        10\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      0.25      0.33         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.67      0.80         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.77      0.56      0.65        18\n",
      "           9       1.00      0.22      0.36         9\n",
      "          10       0.78      0.70      0.74        10\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.75      0.25      0.38        12\n",
      "          13       0.70      0.64      0.67        11\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.75      0.86      0.80         7\n",
      "\n",
      "   micro avg       0.62      0.41      0.50       109\n",
      "   macro avg       0.37      0.26      0.29       109\n",
      "weighted avg       0.60      0.41      0.47       109\n",
      " samples avg       0.21      0.18      0.18       109\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.67      0.40      0.50        10\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      0.25      0.29         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.33      0.50         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.77      0.56      0.65        18\n",
      "           9       0.00      0.00      0.00         9\n",
      "          10       0.86      0.60      0.71        10\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      0.08      0.15        12\n",
      "          13       0.70      0.64      0.67        11\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.83      0.71      0.77         7\n",
      "\n",
      "   micro avg       0.67      0.33      0.44       109\n",
      "   macro avg       0.36      0.20      0.24       109\n",
      "weighted avg       0.56      0.33      0.39       109\n",
      " samples avg       0.18      0.12      0.14       109\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.80      0.40      0.53        10\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.75      1.00      0.86         3\n",
      "           7       0.33      0.33      0.33         3\n",
      "           8       0.77      0.56      0.65        18\n",
      "           9       1.00      0.11      0.20         9\n",
      "          10       0.75      0.30      0.43        10\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        12\n",
      "          13       0.80      0.36      0.50        11\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         5\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.88      1.00      0.93         7\n",
      "\n",
      "   micro avg       0.66      0.30      0.42       109\n",
      "   macro avg       0.30      0.20      0.22       109\n",
      "weighted avg       0.52      0.30      0.35       109\n",
      " samples avg       0.16      0.11      0.12       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For negative sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neg = get_negative_data_frame(df_train,most_common_aspect)\n",
    "df_test_neg = get_negative_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_neg,df_test_neg,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.7375\n",
      "0.725\n",
      "0.7375\n",
      "0.75\n",
      "\n",
      "Average precision:\n",
      "0.0\n",
      "0.15384615384615385\n",
      "0.3333333333333333\n",
      "1.0\n",
      "\n",
      "Average recall:\n",
      "0.0\n",
      "0.07142857142857142\n",
      "0.03571428571428571\n",
      "0.03571428571428571\n",
      "\n",
      "Average f1:\n",
      "0.0\n",
      "0.0975609756097561\n",
      "0.06451612903225806\n",
      "0.0689655172413793\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00        10\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.00      0.00      0.00        28\n",
      "   macro avg       0.00      0.00      0.00        28\n",
      "weighted avg       0.00      0.00      0.00        28\n",
      " samples avg       0.00      0.00      0.00        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.29      0.20      0.24        10\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.15      0.07      0.10        28\n",
      "   macro avg       0.01      0.01      0.01        28\n",
      "weighted avg       0.10      0.07      0.08        28\n",
      " samples avg       0.02      0.03      0.02        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.33      0.10      0.15        10\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.33      0.04      0.06        28\n",
      "   macro avg       0.02      0.01      0.01        28\n",
      "weighted avg       0.12      0.04      0.05        28\n",
      " samples avg       0.01      0.01      0.01        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.10      0.18        10\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      0.04      0.07        28\n",
      "   macro avg       0.05      0.01      0.01        28\n",
      "weighted avg       0.36      0.04      0.06        28\n",
      " samples avg       0.01      0.01      0.01        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For neutral or conflict sentiment classifier\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "df_test = get_data_frame(final_test_text_list,test_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neu = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "df_test_neu = get_neutral_data_frame(df_test,most_common_aspect)\n",
    "\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neu,df_test_neu,X_train_aspect_dtm,X_test_aspect_dtm)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print_metrices(y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a laptop review:\n",
      "\n",
      "This is my first asus laptop. So far i am really enjoying this laptop. 512GB SSD is super fast. Battery life is also good and can last very long. I have no complain on screen quality too as display supports 4k videos. Maybe that is why it costs a lot. This is an expensive laptop and it's price is very high compared to other laptops of similar specs. So, if you have no trouble paying for this laptop, it is pretty good.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aspect Based Sentiment analyis of user's input.\n",
    "user_input=input(\"Enter a laptop review:\\n\\n\")\n",
    "#Preprocessing and vectorizing\n",
    "tagged_user_input = posTag([user_input])\n",
    "filter_tagged_user_input = filterTag(tagged_user_input)\n",
    "\n",
    "user_input_series=pd.Series(filter_tagged_user_input)\n",
    "user_input_series_dtm=vect.transform(user_input_series)\n",
    "\n",
    "predict_aspect= svc.predict(user_input_series_dtm)\n",
    "extra_feature=get_dict_aspect(predict_aspect, most_common_aspect)\n",
    "extra_feature_dtm=DictVectorizer().fit_transform(extra_feature)\n",
    "predict_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_positive = get_positive_data_frame(df_train,most_common_aspect)\n",
    "y_test_pos,y_pred_class_pos,y_pred_class_svc_pos,y_pred_class_lin_svc_pos,y_pred_class_sgd_pos=classify_sentiment(df_train_positive,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_negative = get_negative_data_frame(df_train,most_common_aspect)\n",
    "y_test_neg,y_pred_class_neg,y_pred_class_svc_neg,y_pred_class_lin_svc_neg,y_pred_class_sgd_neg=classify_sentiment(df_train_negative,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_opinion_list=[]\n",
    "df_test = get_data_frame(filter_tagged_user_input,test_opinion_list,most_common_aspect)\n",
    "df_train = get_data_frame(final_train_text_list,train_opinion_list,most_common_aspect)\n",
    "\n",
    "df_train_neutral = get_neutral_data_frame(df_train,most_common_aspect)\n",
    "y_test_neu,y_pred_class_neu,y_pred_class_svc_neu,y_pred_class_lin_svc_neu,y_pred_class_sgd_neu=classify_sentiment(df_train_neutral,df_test,X_train_aspect_dtm,extra_feature_dtm)\n",
    "\n",
    "y_pred_class_svc_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 8, 10, 13]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_positive=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_pos.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_positive.append(i)\n",
    "index_positive  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_negative=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neg.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_negative.append(i)\n",
    "index_negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_neutral=[]\n",
    "for i, (a, b) in enumerate(zip(predict_aspect.tolist()[0], y_pred_class_svc_neu.tolist()[0])):\n",
    "    if a ==1 and b==1:\n",
    "        index_neutral.append(i)\n",
    "index_neutral   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BATTERY_OPERATION_PERFORMANCE: positive',\n",
       " 'DISPLAY_GENERAL: positive',\n",
       " 'LAPTOP_GENERAL: positive',\n",
       " 'LAPTOP_OPERATION_PERFORMANCE: positive',\n",
       " 'LAPTOP_QUALITY: positive']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=[]\n",
    "if index_positive:\n",
    "    for index in index_positive:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": positive\")\n",
    "        \n",
    "if index_negative:\n",
    "    for index in index_negative:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": negative\")\n",
    "        \n",
    "if index_neutral:\n",
    "    for index in index_neutral:\n",
    "        output.append(sorted(most_common_aspect)[index]+\": neutral or conflict\")\n",
    "        \n",
    "        \n",
    "output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
